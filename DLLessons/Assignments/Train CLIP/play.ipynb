{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muthu/miniconda3/envs/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lightning as pl \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from functorch.compile import compiled_function,draw_graph\n",
    "from lightning.pytorch.profilers import PyTorchProfiler\n",
    "from lightning.pytorch.callbacks import (\n",
    "    DeviceStatsMonitor,\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    ModelPruning\n",
    ")\n",
    "from lightning.pytorch.callbacks.progress import TQDMProgressBar\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium' )\n",
    "import os \n",
    "from src.utils import *\n",
    "from src.datamodule import ClipDataModule\n",
    "from src.model import CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ClipDataModule()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Loggers\n",
    "logger:pl_loggers.TensorBoardLogger = pl_loggers.TensorBoardLogger(save_dir='logs/',name= \"lightning_logs\",log_graph=True) \n",
    "\n",
    "## CallBacks\n",
    "call_backs = [\n",
    "    TQDMProgressBar(refresh_rate=10),\n",
    "    ModelCheckpoint(\n",
    "        monitor=\"val_loss\", dirpath=os.path.join('logs','chkpoints'), filename=\"{epoch:02d}\",save_top_k=1,\n",
    "    ),\n",
    "    DeviceStatsMonitor(cpu_stats=True),\n",
    "    LearningRateMonitor(logging_interval='step')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muthu/miniconda3/envs/venv/lib/python3.11/site-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(precision=16, max_epochs=3, accelerator=\"gpu\",logger=logger, profiler='pytorch',callbacks=call_backs,limit_train_batches=0.2,limit_test_batches=0.2,limit_val_batches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type           | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | image_encoder    | ImageEncoder   | 11.2 M | train\n",
      "1 | text_encoder     | TextEncoder    | 66.4 M | train\n",
      "2 | image_projection | ProjectionHead | 197 K  | train\n",
      "3 | text_projection  | ProjectionHead | 263 K  | train\n",
      "------------------------------------------------------------\n",
      "78.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "78.0 M    Total params\n",
      "312.001   Total estimated model params size (MB)\n",
      "200       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/muthu/miniconda3/envs/venv/lib/python3.11/site-packages/lightning/pytorch/loggers/tensorboard.py:191: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muthu/miniconda3/envs/venv/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/3178 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W1021 11:17:52.531806015 collection.cpp:634] Warning: [pl][profile][LightningModule]CLIPModel.optimizer_step (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97%|█████████▋| 3090/3178 [05:19<00:09,  9.67it/s, v_num=2, train_loss=1.060, Mean Train Loss=2.190]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, valid_df = make_train_valid_dfs()\n",
    "model, image_embeddings = get_image_embeddings(valid_df, \"best.pt\")\n",
    "find_matches(model,\n",
    "             image_embeddings.to(\"cuda\"),\n",
    "             query=\"horse running\",\n",
    "             image_filenames=valid_df['image'].values,\n",
    "             n=9)\n",
    "find_matches(model,\n",
    "             image_embeddings.to(\"cuda\"),\n",
    "             query=\"people dancing\",\n",
    "             image_filenames=valid_df['image'].values,\n",
    "             n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataset import get_transforms\n",
    "# test_transform = get_transforms(mode='test')\n",
    "# dataset = CLIPDataset(\n",
    "#         dm.train_df[\"image\"].values,\n",
    "#         dm.train_df[\"caption\"].values,\n",
    "#         tokenizer=dm.tokenizer,\n",
    "#         transforms=test_transform,\n",
    "#     )\n",
    "# dl = torch.utils.data.DataLoader( dataset, batch_size= 1_000, shuffle=True )\n",
    "# batch = next(iter(dl))\n",
    "# print(batch['image'].device)\n",
    "# torch.save(batch['image'], \"10kcpu_imgs.pt\")\n",
    "# training_images =  torch.load('10kcpu_imgs.pt')\n",
    "# training_images.to('cuda:0').shape\n",
    "# features1 = model.cuda().image_encoder( training_images.cuda()[:50,:,:,:] )\n",
    "# features2 = model.cuda().image_projection(features1)\n",
    "# print(features2.shape)\n",
    "# import torchvision\n",
    "# batch['image'].shape\n",
    "# random_image = batch['image'][324]\n",
    "# img_features_1 = model.image_encoder( torchvision.transforms.Resize((64,64))( random_image ).unsqueeze(0).cuda() )\n",
    "# img_features_2 = model.image_projection(img_features_1)\n",
    "# print(random_image.shape, img_features_2.shape)\n",
    "# with torch.no_grad():\n",
    "#     cost = img_features_2 @ features2.T\n",
    "# plt.imshow(random_image.permute(1,2,0).cpu())\n",
    "# plt.show()\n",
    "\n",
    "# print('*'*200)\n",
    "# for i in cost.argsort(dim=-1,descending=True)[:,:5].flatten().cpu():\n",
    "#     plt.imshow(\n",
    "#         torchvision.transforms.Normalize(mean= (-.5,-.5,-.5), std=(1,1,1))(\n",
    "#             training_images[i.item()]\n",
    "#         ).permute(1,2,0)\n",
    "#     )\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
