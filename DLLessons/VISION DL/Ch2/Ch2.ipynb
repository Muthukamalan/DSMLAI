{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check cuda is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH:str = os.path.join(os.environ[\"HOME\"],\"Documents\",\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:09<00:00, 1.07MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 94.7kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:03<00:00, 428kB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 26.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128  #number of images in single go \n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root=DATAPATH, train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root=DATAPATH, train=False,download=True ,transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469, 79)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Notes on our naive model\n",
    "\n",
    "We are going to write a network based on what we have learnt so far.\n",
    "\n",
    "The size of the input image is 28x28x1. We are going to add as many layers as required to reach RF = 32 \"atleast\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstDNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(FirstDNN, self).__init__()\n",
    "    # r_in:1, n_in:28, j_in:1, s:1, r_out:3, n_out:28, j_out:1\n",
    "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "\n",
    "    # r_in:3 , n_in:28 , j_in:1 , s:1 , r_out:5 , n_out:28 , j_out:1\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "    \n",
    "    # r_in:5 , n_in:28 , j_in:1 , s:2 , r_out:6 , n_out:14 , j_out:2\n",
    "    self.pool1 = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    # r_in:6 , n_in:14 , j_in:2 , s:1 , r_out:10 , n_out:14 , j_out:2\n",
    "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "    \n",
    "    # r_in:10 , n_in:14 , j_in:2 , s:1 , r_out:14 , n_out:14 , j_out:2\n",
    "    self.conv4 = nn.Conv2d(128, 256, 3, padding = 1)\n",
    "    \n",
    "    # r_in:14 , n_in:14 , j_in:2 , s:2 , r_out:16 , n_out:7 , j_out:4\n",
    "    self.pool2 = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    # r_in:16 , n_in:7 , j_in:4 , s:1 , r_out:24 , n_out:7 , j_out:4\n",
    "    self.conv5 = nn.Conv2d(256, 512, 3)\n",
    "    \n",
    "    # r_in:24 , n_in:5 , j_in:4 , s:1 , r_out:32 , n_out:3 , j_out:4\n",
    "    self.conv6 = nn.Conv2d(512, 1024, 3)\n",
    "    \n",
    "    # r_in:32 , n_in:3 , j_in:4 , s:1 , r_out:40 , n_out:1 , j_out:4\n",
    "    self.conv7 = nn.Conv2d(1024, 10, 3)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
    "    x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
    "    x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
    "    # DON\"T USE ANY NON-Linearity in Final LAYER\n",
    "    x = self.conv7(x) \n",
    "    x = x.view(-1, 10)\n",
    "    return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116917/3395000630.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FirstDNN                                 [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [32, 28, 28]              320\n",
       "├─Conv2d: 1-2                            [64, 28, 28]              18,496\n",
       "├─MaxPool2d: 1-3                         [64, 14, 14]              --\n",
       "├─Conv2d: 1-4                            [128, 14, 14]             73,856\n",
       "├─Conv2d: 1-5                            [256, 14, 14]             295,168\n",
       "├─MaxPool2d: 1-6                         [256, 7, 7]               --\n",
       "├─Conv2d: 1-7                            [512, 5, 5]               1,180,160\n",
       "├─Conv2d: 1-8                            [1024, 3, 3]              4,719,616\n",
       "├─Conv2d: 1-9                            [10, 1, 1]                92,170\n",
       "==========================================================================================\n",
       "Total params: 6,379,786\n",
       "Trainable params: 6,379,786\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 18.74\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 1.38\n",
       "Params size (MB): 25.52\n",
       "Estimated Total Size (MB): 26.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FirstDNN().to(device)\n",
    "summary(model, input_size=(1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]/tmp/ipykernel_116917/3395000630.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "loss=0.09321117401123047 batch_id=468: 100%|██████████| 469/469 [00:18<00:00, 25.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0541, Accuracy: 9826/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.06701067835092545 batch_id=468: 100%|██████████| 469/469 [00:18<00:00, 25.79it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0369, Accuracy: 9880/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, 3):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
